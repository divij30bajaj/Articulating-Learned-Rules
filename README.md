## Articulating-Learned-Rules

This work is done as a submission to Owain Evans' MATS stream for the Winter Cohort 2024-25. The task is to evaluate if LLMs can learn and articulate simple classification rules. For this exercise, the preliminary experiemts were done using 6 LLMs - GPT-4, GPT-4o, Claude-3.5-Sonnet, Llama3-70B, Llama-3.1-70B and Gemini-1.5-Pro. A total of 6 classification tasks were chosen:
The input is labeled as ‘True’ if and only if
1. The input contains a time in a 12-hour format: Half of the input examples mentioned a random time in a 12-hour format (HH:MM AM/PM) and the other half mentioned a random time in a 24-hour format (HHMM hours). The query was randomly chosen to be from one of the two formats.
2. The input is enclosed in double dollar signs ($$): Half of the input examples are enclosed in double dollar signs. For example, “$$<Sentence>$$”. The other half is kept unchanged and are simple and short English sentences. The query was randomly chosen to be from one of the two kinds.
3. The first word in the input is in all uppercase letters: Half of the input examples were simple and short English sentences, while the other half had the first word capitalized.
4. The input mentions apples: 50% of the input examples were sentences talking about apples, while the other half were similar sentences, but with “apples” replaced by another fruit from a pool of 5 fruits.
5. The input contains numbers spelled out in words: All input examples mention some number between 0 and 10. Half of these input examples mention the number in words, while the other half mentions in digits.
6. The input contains two sentences: Half of the input examples were simple and short English sentences, while the other half was a concatenation of two sentences of similar kinds.

All model APIs are initialized and queried in `models.py`. Replace `<API-KEY>` with your own API key for each LLM API service.

To run the code from scratch, the first step is to generate prompts for each task defined in `tasks.py`. To do so, run the following command with the desired values of arguments:
`python generate_data.py --num_examples_per_prompt=32 --num_prompts=100`

The above code uses some simple and short English sentences that were generated by ChatGPT. These sentences are stored in the `inputs` directory. The output of the above script will be stored in the `data` directory. 

